{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a77b4151",
   "metadata": {},
   "source": [
    "#### Стандартная версия\n",
    "Нужно реализовать rest api на базе flask в google colab.\n",
    "\n",
    "выбрать себе датасет (который интересен или нравится больше всего, можно глянуть здесь https://economic-caper-a4c.notion.site/d062c410b90145bca90fc23b1348c813), сделать pipeline (преобразования + модель), сохранить его на диск. Если не хочется пайплайн, то можно без него, но так вам же будет удобнее потом вызывать его из кода сервиса.\n",
    "Реализовать ноутбук с сервером\n",
    "Реализовать ноутбук с клиентом"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcdd63d",
   "metadata": {},
   "source": [
    "# Интеграция.Итоговый проект"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709d68b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dill\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#working with text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#normalizing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#pipeline\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "\n",
    "#imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "729c7c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head(3)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b165d1",
   "metadata": {},
   "source": [
    "##### Я так понял, что датасет на выявление токсичности в тексте.Задача бинарной классификации .Целевая переменная---identity_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d0db93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    158166\n",
       "1      1405\n",
       "Name: identity_hate, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['identity_hate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae098f6",
   "metadata": {},
   "source": [
    "##### Наблюдается дисбаланс класса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce058df6",
   "metadata": {},
   "source": [
    "#### Разделим данные на train/test и сохраним тестовую выборку на диск!!!(X_test.csv, y_test.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20581805",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df['identity_hate'],\n",
    "                                                    test_size=0.33, random_state=42)# разбиение 1:3\n",
    "# save test\n",
    "X_test.to_csv(\"X_test.csv\", index=None)\n",
    "y_test.to_csv(\"y_test.csv\", index=None)\n",
    "\n",
    "# save train\n",
    "X_train.to_csv(\"X_train.csv\", index=None)\n",
    "y_train.to_csv(\"y_train.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b11af7",
   "metadata": {},
   "source": [
    "##### Напишем классы для пайплайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ac6a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin): # Выбор одного признака\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "\n",
    "class TextImputer(BaseEstimator, TransformerMixin): # Класс заполнения пропусков в текстовом признаке 'comment_text'\n",
    "    def __init__(self, key, value):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X[self.key] = X[self.key].fillna(self.value) # меняем пропуски на значение\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c0924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 'comment_text'\n",
    "target = 'identity_hate'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7018dee",
   "metadata": {},
   "source": [
    "##### Соберем кусок, ответственный за feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2293d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine\n",
    "comment_text = Pipeline([\n",
    "                ('imputer', TextImputer('comment_text', '')),         # меняем незаполненный признак на пустую строку ''\n",
    "                ('selector', ColumnSelector(key='comment_text')),\n",
    "                ('tfidf', TfidfVectorizer())              # прогоняем признак через Tfidf векторайзер\n",
    "            ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feats = FeatureUnion([('comment_text', comment_text)])\n",
    "                      \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae43035",
   "metadata": {},
   "source": [
    "##### Добавим простейший классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cf1c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ea939544cf2a>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.key] = X[self.key].fillna(self.value) # меняем пропуски на значение\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('comment_text',\n",
       "                                                 Pipeline(steps=[('imputer',\n",
       "                                                                  TextImputer(key='comment_text',\n",
       "                                                                              value='')),\n",
       "                                                                 ('selector',\n",
       "                                                                  ColumnSelector(key='comment_text')),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfVectorizer())]))])),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', feats),\n",
    "    ('classifier', LogisticRegression()), #  в качестве классификатора берем логистическую регрессию,Tfidf позволяет нам это сделать\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fddfe7e",
   "metadata": {},
   "source": [
    "#### Сохраним модель (пайплайн).Один признак и одна модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b127de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"logreg_pipeline.dill\", \"wb\") as f:  \n",
    "    dill.dump(pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9e6ab6",
   "metadata": {},
   "source": [
    "##### Сохранем модель в формате dill весь наш пайплайн,это избавляет нас от лишних ошибок в будущем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c29fa8",
   "metadata": {},
   "source": [
    "### Шаг 2.Предсказание (Predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1e4ba0",
   "metadata": {},
   "source": [
    "##### Проверка работоспособности и качества пайплайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0253f53",
   "metadata": {},
   "source": [
    "##### Загружаем модель напрямую и проверяем на отложенной(тестовой ) выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6934e6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0d54562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7ca72b5b9c688e9e</td>\n",
       "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c03f72fd8f8bf54f</td>\n",
       "      <td>Carioca RFA \\n\\nThanks for your support on my ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9e5b8e8fc1ff2e84</td>\n",
       "      <td>\"\\n\\n Birthday \\n\\nNo worries, It's what I do ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  7ca72b5b9c688e9e  Geez, are you forgetful!  We've already discus...      0   \n",
       "1  c03f72fd8f8bf54f  Carioca RFA \\n\\nThanks for your support on my ...      0   \n",
       "2  9e5b8e8fc1ff2e84  \"\\n\\n Birthday \\n\\nNo worries, It's what I do ...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0a1d64",
   "metadata": {},
   "source": [
    "##### Теперь загрузим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "778ffb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logreg_pipeline.dill', 'rb') as in_strm:\n",
    "    pipeline = dill.load(in_strm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91b69cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('comment_text',\n",
       "                                                 Pipeline(steps=[('imputer',\n",
       "                                                                  TextImputer(key='comment_text',\n",
       "                                                                              value='')),\n",
       "                                                                 ('selector',\n",
       "                                                                  ColumnSelector(key='comment_text')),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfVectorizer())]))])),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb63342",
   "metadata": {},
   "source": [
    "##### Здесь наши признаки,где мы заполняем пустоты при помощи Tfidf векторайзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "684bb22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipeline.predict_proba(X_test)[:, 1]  # предсказание вероятности,чтобы подообрать необходимую отсечку\n",
    "\n",
    "pred_df = pd.DataFrame({'preds': preds})\n",
    "pred_df.to_csv(\"test_predictions.csv\", index=None) # сохраняем предсказание в файле,хорошая стратегия для логирования при обучении многих моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85d316b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01481612, 0.00149461, 0.00782364, 0.00187916, 0.00287763,\n",
       "       0.00197865, 0.00567359, 0.01054992, 0.000868  , 0.00685097])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5911b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.15290741374698139, F-Score=0.442, Precision=0.490, Recall=0.403\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, preds) # подбираем оптимальную отсечку 'thresholds'\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print(f'Best Threshold={thresholds[ix]}, F-Score={fscore[ix]:.3f}, Precision={precision[ix]:.3f}, Recall={recall[ix]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8ad4c",
   "metadata": {},
   "source": [
    "##### Метрики получились не очень хорошие,вероятно из-за того,что использовали один признак"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b51010",
   "metadata": {},
   "source": [
    "### Шаг 3.Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ffb28",
   "metadata": {},
   "source": [
    "##### Flask\n",
    "\n",
    "Тут будет сервис для обработки запросов на Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94b7815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3513f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [27/Apr/2022 21:55:03] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [27/Apr/2022 21:55:03] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [27/Apr/2022 21:55:18] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "# Пробный запуск Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route(\"/a\")\n",
    "def hello():\n",
    "    return \"Hello World!\"\n",
    "\n",
    "if __name__ == '__main__':  # попросили меня пользоваться другим сервером,каким---не знаю.Машина встала\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a7ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b4767",
   "metadata": {},
   "source": [
    "### Создаем сервис для обработки запросов к модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf70ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем обученные модели\n",
    "with open('logreg_pipeline.dill', 'rb') as in_strm:\n",
    "    model = dill.load(in_strm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d0e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b52c51a",
   "metadata": {},
   "source": [
    "##### Запускаем сервис"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e3387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработчики и запуск Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\"])  # главный путь\n",
    "def general():\n",
    "    return \"Welcome to prediction process\"\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['POST'])  # метод PREDICT,ждём JSON\n",
    "def predict():\n",
    "    data = {\"success\": False}  # формируем словарь в JSON и отправляем клиенту.False по дефолту\n",
    "\n",
    "    # ensure an image was properly uploaded to our endpoint\n",
    "    comment_text = \"\", \"\", \"\"\n",
    "    request_json = request.get_json()\n",
    "    \n",
    "    if request_json[\"comment_text\"]:\n",
    "        comment_text = request_json['comment_text']\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(comment_text)  \n",
    "    preds = model.predict_proba(pd.DataFrame({\"comment_text\": [comment_text]\n",
    "                                              \n",
    "                                              }))   # формируем один объект для предсказания вероятности по датафрейму\n",
    "    data[\"predictions\"] = preds[:, 1][0] # 1-целевой класс,0-это наш объект.В данном случае он один--comment_text\n",
    "    data[\"comment_text\"] = comment_text\n",
    "        # indicate that the request was a success\n",
    "    data[\"success\"] = True  # модель предсказала\n",
    "    print('OK')\n",
    "\n",
    "        # return the data dictionary as a JSON response\n",
    "    return jsonify(data)    # перевод словаря в JSON\n",
    "\n",
    "\n",
    "if __name__ == '__main__':    # запуск приложения\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f71cbf",
   "metadata": {},
   "source": [
    "### Строим запрос к нашему сервису"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5005dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import urllib.request\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c8e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример данных\n",
    "data = ( \n",
    "    \"Stylect is a dynamic startup that helps helps women discover and buy shoes. We’re a small team based in London that has previously worked at Google, Techstars, Pixelmator and Rocket Internet.We place a high premium on simplicity no matter what we’re working on (i.e. design, programming, marketing). We’re also a team that ships fast. We built version 1 of our app in a week, the next release (built in a month) was featured in the Apple Appstore Italy as a best new fashion app. Fast release cycles are challenging, but also very fun - which is why we love them.\\xa0As we’ve grown, the projects that we’re working on have grown both in scale and in technical complexity. \\xa0Stylect is looking for someone who can help us improve our backend which gathers product data; analyses/categorizes it; and shows it to thousands of users daily. Each step in the process has unique challenges that demands a strong technical background.\",\n",
    "    \"ustwo offers you the opportunity to be yourself, whilst delivering the best work on the planet for some of the biggest and most innovative brands. A culture thriving on collaboration underpins what is an amazing work smart/ live well environment.We genuinely care about the work that we deliver and the people who help make it all possible. We only invest in projects, people and practices that we believe in, to ensure we remain excited about every opportunity.\",\n",
    "    \"We are negotiable on salary and there is the potential for equity for the right candidate.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56451f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# формируем запрос\n",
    "def send_json(x):\n",
    "    comment_text = x\n",
    "    #print(comment_text)  # наш признак\n",
    "    body = {\n",
    "        'comment_text': comment_text    # тело запроса\n",
    "        \n",
    "        }\n",
    "    myurl = '/predict'\n",
    "    headers = {'content-type': 'application/json; charset=utf-8'}  # шапка\n",
    "    response = requests.post(myurl, json=body, headers=headers) # запрос по нашему пути(Post),телу запроса,шапкой\n",
    "    return response.json()['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1db0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обращение к серверу с запросом из одного набора (его построили руками выше - data)\n",
    "response = send_json(data)\n",
    "print('предсказание', response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef26899",
   "metadata": {},
   "source": [
    "##### Здесь должно быть предсказание.Но из-за того,что компьютер встал,результат не виден"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a37069",
   "metadata": {},
   "source": [
    "### Сделаем обработку массы запросов:\n",
    "\n",
    "1. загрузим данные X_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffbf3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from urllib import request, parse\n",
    "\n",
    "\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffcd861",
   "metadata": {},
   "source": [
    "##### 2. Передаем запрос одиночный из наших данных и посмотрим на ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e775160",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = send_json(X_test[['comment_text']].iloc[0,:])\n",
    "response   # должна быть какая-то вероятность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded6aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[['comment_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54fa641",
   "metadata": {},
   "source": [
    "##### 3. Сделаем N запросов и оценим время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b1958",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = X_test[\n",
    "                     ['comment_text']\n",
    "                     ].iloc[:N].apply(lambda x: send_json(x), axis=1) # здесь заданы 50 объектов,каждый объект отправим на предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a60065",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48301594",
   "metadata": {},
   "source": [
    "##### 4. Посчитаем метрику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fd3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head() # посчитаем метрику identity_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test[:N], predictions)\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print(f'Best Threshold={thresholds[ix]}, F-Score={fscore[ix]:.3f}, Precision={precision[ix]:.3f}, Recall={recall[ix]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe630357",
   "metadata": {},
   "outputs": [],
   "source": [
    "Итог: Flask слишком тяжёлый для компа,он завис и результаа я не увидел."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc30e47c",
   "metadata": {},
   "source": [
    "##### Тестовый клиент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49238b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример данных.Создание тестового объекта и формирование тела запроса\n",
    "comment_text_data = ( \n",
    "    \"Stylect is a dynamic startup that helps helps women discover and buy shoes. We’re a small team based in London that has previously worked at Google, Techstars, Pixelmator and Rocket Internet.We place a high premium on simplicity no matter what we’re working on (i.e. design, programming, marketing). We’re also a team that ships fast. We built version 1 of our app in a week, the next release (built in a month) was featured in the Apple Appstore Italy as a best new fashion app. Fast release cycles are challenging, but also very fun - which is why we love them.\\xa0As we’ve grown, the projects that we’re working on have grown both in scale and in technical complexity. \\xa0Stylect is looking for someone who can help us improve our backend which gathers product data; analyses/categorizes it; and shows it to thousands of users daily. Each step in the process has unique challenges that demands a strong technical background.\",\n",
    "    \"ustwo offers you the opportunity to be yourself, whilst delivering the best work on the planet for some of the biggest and most innovative brands. A culture thriving on collaboration underpins what is an amazing work smart/ live well environment.We genuinely care about the work that we deliver and the people who help make it all possible. We only invest in projects, people and practices that we believe in, to ensure we remain excited about every opportunity.\",\n",
    "    \"We are negotiable on salary and there is the potential for equity for the right candidate.\"\n",
    ")\n",
    "\n",
    "body = {\n",
    "        'comment_text': comment_text \n",
    "        \n",
    "        \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with app.test_client() as t:\n",
    "    response = t.post('/predict', json=body)\n",
    "    json_data = response.get_json()\n",
    "\n",
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d298208c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
